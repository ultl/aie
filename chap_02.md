# **2. Understanding Foundation Models**

- **Training Data**
  - Multilingual Models
  - Domain-Specific Models
- **Modeling**
  - Model Architecture
  - Model Size
- **Post-Training**
  - Supervised Finetuning
  - Preference Finetuning
- **Sampling**
  - Sampling Fundamentals
  - Sampling Strategies
  - Test Time Compute
  - Structured Outputs
  - The Probabilistic Nature of AI

# Dataset Engineering

- Dataset Engineering: curating, generating, and annotating datasets for
  training AI models.
  - Annotated datasets: datasets with labels or annotations that provide
    additional information about the data.
  - Dataset curation: the process of selecting, organizing, and managing
    datasets to ensure their quality and relevance for training AI models.
  - Dataset generation: the process of creating new datasets, often using
    techniques like data augmentation or synthetic data generation.

- Traditional ML engineering works with tabular data and structured data, while
  foundation models work with unstructured data like text, images, and audio.
  - Many argue that because models are now commodities, the focus should be on
    dataset engineering rather than model engineering. => how much data you need
    depends on the adapter technique you use.

- Inference optimization: the process of optimizing the performance of AI models
  during inference, including techniques like quantization, pruning, and
  distillation.

# AI Engineering Stack In detail

- **Application Development**
  - AI Interface
  - Prompt Engineering
  - Context Construction
  - Evaluation

- **Model Development**
  - Inference Optimization
  - Dataset Engineering
  - Model Training
  - Evaluation

- **Infrastructure**
  - Compute Management
  - Data Management
  - Serving
  - Monitoring
